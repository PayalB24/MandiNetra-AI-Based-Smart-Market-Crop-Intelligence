{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8519cae-a703-469d-ac4f-f5f1e8c99381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from joblib import dump, load\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5fb4ff-a082-41c9-b438-a2a7f5d6d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/fruits/chikoo.csv\")\n",
    "df = df.rename(columns={'t': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60bc73-c68c-40f7-b18a-c4b8430c99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
    "\n",
    "# Check how many rows were successfully converted\n",
    "total = len(df)\n",
    "converted = df['date'].notna().sum()\n",
    "failed = total - converted\n",
    "\n",
    "print(f\"‚úÖ Successfully converted {converted}/{total} dates.\")\n",
    "if failed > 0:\n",
    "    print(f\"‚ö†Ô∏è {failed} rows could not be parsed ‚Äî check these:\")\n",
    "    print(df[df['date'].isna()].head())\n",
    "\n",
    "# Sort chronologically (important before feature extraction)\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# Extract date-based features\n",
    "df['Year'] = df['date'].dt.year\n",
    "df['Month'] = df['date'].dt.month\n",
    "df['Day'] = df['date'].dt.day\n",
    "df['DayOfWeek'] = df['date'].dt.dayofweek\n",
    "df['WeekOfYear'] = df['date'].dt.isocalendar().week\n",
    "\n",
    "print(\"\\nüìÖ Date features extracted successfully!\")\n",
    "print(df[['date', 'Year', 'Month', 'Day', 'DayOfWeek', 'WeekOfYear']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0e9e2-5490-4eeb-817d-625aeeb7be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date features\n",
    "df['Year'] = df['date'].dt.year\n",
    "df['Month'] = df['date'].dt.month\n",
    "df['Day'] = df['date'].dt.day\n",
    "df['DayOfWeek'] = df['date'].dt.dayofweek\n",
    "df['WeekOfYear'] = df['date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90454a2f-8094-4fbf-950b-2763a2d8156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcf28e-616c-4059-8968-1309ebf1a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical variables\n",
    "le_district = LabelEncoder()\n",
    "le_market = LabelEncoder()\n",
    "\n",
    "df['district_encoded'] = le_district.fit_transform(df['district_name'])\n",
    "df['market_encoded'] = le_market.fit_transform(df['market_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043eadc-e813-4eba-9aef-8aae4a0691dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these encoders for the API\n",
    "pickle.dump(le_district, open('../models/chikoodistrict_encoder.pkl', 'wb'))\n",
    "pickle.dump(le_market, open('../models/chikoomarket_encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28fa7a6-2aa4-485c-b54d-ea7ef1d0d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning - remove unrealistic prices\n",
    "print(f\"Before cleaning: {len(df)} records\")\n",
    "df = df[(df['p_modal'] > 500) & (df['p_modal'] < 10000)]\n",
    "df = df[(df['p_min'] > 0) & (df['p_min'] < 10000)]\n",
    "df = df[(df['p_max'] > 0) & (df['p_max'] < 10000)]\n",
    "print(f\"After cleaning: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7705c6-e66e-469f-8ba2-65452e9a8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df['p_min'] = df['p_min'].fillna(df['p_modal'] * 0.9)  # p_min ‚âà 90% of modal\n",
    "df['p_max'] = df['p_max'].fillna(df['p_modal'] * 1.1)  # p_max ‚âà 110% of modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58026c20-2fe0-48f7-af13-3cc55091411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CORRECT FEATURE SET - All 9 features your API expects\n",
    "features = [\n",
    "    'market_id', 'state_id', 'district_id',  # Location IDs\n",
    "    'p_min', 'p_max',                        # Price range\n",
    "    'Year', 'Month', 'Day',                  # Date components\n",
    "    'district_encoded'                       # Encoded district\n",
    "]\n",
    "\n",
    "target = 'p_modal'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "print(f\"Features used: {features}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd3036-a625-4474-b7ea-df3e365b8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ PROPER TIME-BASED SPLIT\n",
    "split_date = df['date'].quantile(0.8)  # 80% for training, 20% for testing\n",
    "train_mask = df['date'] < split_date\n",
    "test_mask = df['date'] >= split_date\n",
    "\n",
    "X_train, X_test = X[train_mask], X[test_mask]\n",
    "y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "print(f\"Train period: {df[train_mask]['date'].min()} to {df[train_mask]['date'].max()}\")\n",
    "print(f\"Test period: {df[test_mask]['date'].min()} to {df[test_mask]['date'].max()}\")\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03081f-a14f-4ca7-8696-98821d12a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "my_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12f984-4ef6-4256-a51b-9aee4866a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit pipeline on training data only\n",
    "X_train_prepared = my_pipeline.fit_transform(X_train)\n",
    "X_test_prepared = my_pipeline.transform(X_test)\n",
    "\n",
    "print(f\"Prepared train shape: {X_train_prepared.shape}\")\n",
    "print(f\"Prepared test shape: {X_test_prepared.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04209265-6dc6-4e1c-84a2-3bec4b3da7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5\n",
    ")\n",
    "\n",
    "model.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a651c8a-e85f-4722-93b6-eb61e24b73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred_train = model.predict(X_train_prepared)\n",
    "y_pred_test = model.predict(X_test_prepared)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nüìä Model Performance:\")\n",
    "print(f\"Train RMSE: {train_rmse:.2f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f}\")\n",
    "print(f\"Train R¬≤: {train_r2:.4f}\")\n",
    "print(f\"Test R¬≤: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99ad61-7544-41c9-b4db-feedd9dca349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc085b-21f2-47dc-b45c-9cfc3bf513e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross Validation\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = cross_val_score(model, X_train_prepared, y_train, \n",
    "                           scoring='neg_mean_squared_error', cv=tscv)\n",
    "cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "print(f\"\\nüìà Time Series CV RMSE: {cv_rmse_scores.mean():.2f} (¬±{cv_rmse_scores.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97847f6f-9e12-4082-98cf-491a134d840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and pipeline\n",
    "dump(model, '../models/chikoo_model.joblib')\n",
    "pickle.dump(model, open('../models/chikoo_model.pkl', 'wb'))\n",
    "pickle.dump(my_pipeline, open('../models/chikoo_preprocessor.pkl', 'wb'))\n",
    "\n",
    "print(\"\\nüíæ Model and pipeline saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a67337-44c2-4de7-af29-19eaff2f8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with correct features\n",
    "sample_data = X_test.iloc[:3]\n",
    "print(f\"\\nüß™ Sample test data shape: {sample_data.shape}\")\n",
    "prepared_sample = my_pipeline.transform(sample_data)\n",
    "predictions = model.predict(prepared_sample)\n",
    "\n",
    "print(\"Sample predictions:\", predictions)\n",
    "print(\"Actual values:\", y_test.iloc[:3].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbac66-9211-4447-8c3d-53150f670f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for the API\n",
    "district_mapping = dict(zip(le_district.classes_, range(len(le_district.classes_))))\n",
    "market_mapping = df.groupby('market_name')['market_id'].first().to_dict()\n",
    "\n",
    "print(f\"\\nüåç District mappings: {list(district_mapping.keys())[:5]}...\")\n",
    "print(f\"üè™ Market mappings: {list(market_mapping.keys())[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc46eb9-09a9-4818-96ad-f001e12e03d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ee7fa-3cd8-4fe0-980a-affacedb20c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ca897-7d7d-4d70-ac79-cafa6b4e508d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
