{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a3b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from joblib import dump, load\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b370c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/vegetables/cabbage.csv\")\n",
    "df = df.rename(columns={'t': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cfce467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully converted 57711/57711 dates.\n",
      "\n",
      "üìÖ Date features extracted successfully!\n",
      "           date  Year  Month  Day  DayOfWeek  WeekOfYear\n",
      "8634 2019-01-01  2019      1    1          1           1\n",
      "8635 2019-01-01  2019      1    1          1           1\n",
      "8633 2019-01-01  2019      1    1          1           1\n",
      "8632 2019-01-01  2019      1    1          1           1\n",
      "8636 2019-01-01  2019      1    1          1           1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_16936\\97241943.py:1: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_16936\\97241943.py:1: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True, infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
    "\n",
    "# Check how many rows were successfully converted\n",
    "total = len(df)\n",
    "converted = df['date'].notna().sum()\n",
    "failed = total - converted\n",
    "\n",
    "print(f\"‚úÖ Successfully converted {converted}/{total} dates.\")\n",
    "if failed > 0:\n",
    "    print(f\"‚ö†Ô∏è {failed} rows could not be parsed ‚Äî check these:\")\n",
    "    print(df[df['date'].isna()].head())\n",
    "\n",
    "# Sort chronologically (important before feature extraction)\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# Extract date-based features\n",
    "df['Year'] = df['date'].dt.year\n",
    "df['Month'] = df['date'].dt.month\n",
    "df['Day'] = df['date'].dt.day\n",
    "df['DayOfWeek'] = df['date'].dt.dayofweek\n",
    "df['WeekOfYear'] = df['date'].dt.isocalendar().week\n",
    "\n",
    "print(\"\\nüìÖ Date features extracted successfully!\")\n",
    "print(df[['date', 'Year', 'Month', 'Day', 'DayOfWeek', 'WeekOfYear']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae33068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date features\n",
    "df['Year'] = df['date'].dt.year\n",
    "df['Month'] = df['date'].dt.month\n",
    "df['Day'] = df['date'].dt.day\n",
    "df['DayOfWeek'] = df['date'].dt.dayofweek\n",
    "df['WeekOfYear'] = df['date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa38306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57711 entries, 8634 to 43741\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           57711 non-null  datetime64[ns]\n",
      " 1   cmdty          57711 non-null  object        \n",
      " 2   market_id      57711 non-null  int64         \n",
      " 3   market_name    57711 non-null  object        \n",
      " 4   state_id       57711 non-null  int64         \n",
      " 5   state_name     57711 non-null  object        \n",
      " 6   district_id    57711 non-null  int64         \n",
      " 7   district_name  57711 non-null  object        \n",
      " 8   variety        57711 non-null  object        \n",
      " 9   p_min          57711 non-null  int64         \n",
      " 10  p_max          57711 non-null  int64         \n",
      " 11  p_modal        57711 non-null  int64         \n",
      " 12  Year           57711 non-null  int32         \n",
      " 13  Month          57711 non-null  int32         \n",
      " 14  Day            57711 non-null  int32         \n",
      " 15  DayOfWeek      57711 non-null  int32         \n",
      " 16  WeekOfYear     57711 non-null  UInt32        \n",
      "dtypes: UInt32(1), datetime64[ns](1), int32(4), int64(6), object(5)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c698b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical variables\n",
    "le_district = LabelEncoder()\n",
    "le_market = LabelEncoder()\n",
    "\n",
    "df['district_encoded'] = le_district.fit_transform(df['district_name'])\n",
    "df['market_encoded'] = le_market.fit_transform(df['market_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f11603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these encoders for the API\n",
    "pickle.dump(le_district, open('../models/bringaldistrict_encoder.pkl', 'wb'))\n",
    "pickle.dump(le_market, open('../models/bringalmarket_encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f598038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: 57711 records\n",
      "After cleaning: 46920 records\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning - remove unrealistic prices\n",
    "print(f\"Before cleaning: {len(df)} records\")\n",
    "df = df[(df['p_modal'] > 500) & (df['p_modal'] < 10000)]\n",
    "df = df[(df['p_min'] > 0) & (df['p_min'] < 10000)]\n",
    "df = df[(df['p_max'] > 0) & (df['p_max'] < 10000)]\n",
    "print(f\"After cleaning: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdf6a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df['p_min'] = df['p_min'].fillna(df['p_modal'] * 0.9)  # p_min ‚âà 90% of modal\n",
    "df['p_max'] = df['p_max'].fillna(df['p_modal'] * 1.1)  # p_max ‚âà 110% of modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "851e4c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used: ['market_id', 'state_id', 'district_id', 'p_min', 'p_max', 'Year', 'Month', 'Day', 'district_encoded']\n",
      "Feature matrix shape: (46920, 9)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ CORRECT FEATURE SET - All 9 features your API expects\n",
    "features = [\n",
    "    'market_id', 'state_id', 'district_id',  # Location IDs\n",
    "    'p_min', 'p_max',                        # Price range\n",
    "    'Year', 'Month', 'Day',                  # Date components\n",
    "    'district_encoded'                       # Encoded district\n",
    "]\n",
    "\n",
    "target = 'p_modal'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "print(f\"Features used: {features}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae010fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period: 2019-01-01 00:00:00 to 2024-07-02 00:00:00\n",
      "Test period: 2024-07-03 00:00:00 to 2025-09-20 00:00:00\n",
      "Train size: 37528, Test size: 9392\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ PROPER TIME-BASED SPLIT\n",
    "split_date = df['date'].quantile(0.8)  # 80% for training, 20% for testing\n",
    "train_mask = df['date'] < split_date\n",
    "test_mask = df['date'] >= split_date\n",
    "\n",
    "X_train, X_test = X[train_mask], X[test_mask]\n",
    "y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "print(f\"Train period: {df[train_mask]['date'].min()} to {df[train_mask]['date'].max()}\")\n",
    "print(f\"Test period: {df[test_mask]['date'].min()} to {df[test_mask]['date'].max()}\")\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94dfc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "my_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a56d8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared train shape: (37528, 9)\n",
      "Prepared test shape: (9392, 9)\n"
     ]
    }
   ],
   "source": [
    "# Fit pipeline on training data only\n",
    "X_train_prepared = my_pipeline.fit_transform(X_train)\n",
    "X_test_prepared = my_pipeline.transform(X_test)\n",
    "\n",
    "print(f\"Prepared train shape: {X_train_prepared.shape}\")\n",
    "print(f\"Prepared test shape: {X_test_prepared.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873dc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5\n",
    ")\n",
    "\n",
    "model.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred_train = model.predict(X_train_prepared)\n",
    "y_pred_test = model.predict(X_test_prepared)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nüìä Model Performance:\")\n",
    "print(f\"Train RMSE: {train_rmse:.2f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f}\")\n",
    "print(f\"Train R¬≤: {train_r2:.4f}\")\n",
    "print(f\"Test R¬≤: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056fc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross Validation\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = cross_val_score(model, X_train_prepared, y_train, \n",
    "                           scoring='neg_mean_squared_error', cv=tscv)\n",
    "cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "print(f\"\\nüìà Time Series CV RMSE: {cv_rmse_scores.mean():.2f} (¬±{cv_rmse_scores.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with correct features\n",
    "sample_data = X_test.iloc[:3]\n",
    "print(f\"\\nüß™ Sample test data shape: {sample_data.shape}\")\n",
    "prepared_sample = my_pipeline.transform(sample_data)\n",
    "predictions = model.predict(prepared_sample)\n",
    "\n",
    "print(\"Sample predictions:\", predictions)\n",
    "print(\"Actual values:\", y_test.iloc[:3].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for the API\n",
    "district_mapping = dict(zip(le_district.classes_, range(len(le_district.classes_))))\n",
    "market_mapping = df.groupby('market_name')['market_id'].first().to_dict()\n",
    "\n",
    "print(f\"\\nüåç District mappings: {list(district_mapping.keys())[:5]}...\")\n",
    "print(f\"üè™ Market mappings: {list(market_mapping.keys())[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721ff57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfed48-922e-4871-baec-9b83a03c38eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206bb59-74dc-40e0-93af-92e8d9361ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
